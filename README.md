# ğŸ“¦ Learning from Demonstration: 3D Bin Packing with LLM Guidance

This project implements a **3D bin packing simulation** powered by **Learning from Demonstrations (LfD)** and **LLM guidance**.  
It allows you to **record demonstrations**, **process them into training-ready datasets**, and **fine-tune a model** using **LoRA / QLoRA** for efficient training on limited hardware.

---

## ğŸš€ Features
- **3D Bin Packing Environment** â€“ Simulates placing boxes of various sizes into a bin.
- **LLM-Generated Placement Paths** â€“ Use GPT-based models to generate packing strategies.
- **Demonstration Recording** â€“ Save human or LLM-generated runs for training.
- **Dataset Processing** â€“ Convert raw demonstrations into tokenized datasets.
- **LoRA & QLoRA Fine-Tuning** â€“ Efficiently fine-tune large language models on recorded data.
- **Replay Mode** â€“ Visualize saved runs for debugging or presentations.

---

## ğŸ›  Installation

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/yourusername/learning-from-demonstration.git
cd learning-from-demonstration
```

### 2ï¸âƒ£ Create a Conda Environment
```bash
conda create -n lfd python=3.11
conda activate lfd
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ“‚ Project Structure
```
learning-from-demonstration/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ demos/        # Recorded demonstration datasets
â”‚   â”‚   â””â”€â”€ binpack_lfd.jsonl   # Main dataset (JSON Lines)
â”‚   â”œâ”€â”€ runs/         # Individual demonstration run logs
â”‚   â””â”€â”€ processed/    # Training-ready datasets
â”‚
â”œâ”€â”€ envs/
â”‚   â””â”€â”€ bin_env.py    # 3D bin-packing simulation environment
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ sft_prepare.py   # Dataset preparation for fine-tuning
â”‚   â”œâ”€â”€ train_lora.py    # LoRA/QLoRA training script
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ main.py           # Entry point for recording demonstrations
â””â”€â”€ README.md
```

---

## ğŸ–¥ Usage

### 1ï¸âƒ£ Record Demonstrations
Run the main script to generate and save demonstrations:
```bash
python main.py
```
This will produce a `binpack_lfd.jsonl` file in `data/demos/`.

---

### 2ï¸âƒ£ Replay Demonstrations
Visualize recorded placements:
```bash
python replay.py --file data/demos/binpack_lfd.jsonl
```

---

### 3ï¸âƒ£ Prepare Dataset for Training
Convert raw demonstrations into a processed dataset:
```bash
python training/sft_prepare.py
```
Output will be saved in `data/processed/`.

---

### 4ï¸âƒ£ Fine-Tune with LoRA / QLoRA
Example for QLoRA fine-tuning:
```bash
python training/train_lora.py     --model meta-llama/Llama-3.2-1B     --dataset_dir data/processed     --output_dir models/llama3.2-qlora
```

---

## ğŸ”‘ Hugging Face Authentication
If your model requires authentication:
```bash
huggingface-cli login
```
Make sure you have a **valid read token** from Hugging Face.

---

## ğŸ“Š Example Workflow
1. **Record** â€“ Use `main.py` to create bin packing runs.
2. **Process** â€“ Run `sft_prepare.py` to tokenize and store data.
3. **Fine-Tune** â€“ Train with `train_lora.py` using QLoRA for memory efficiency.
4. **Deploy** â€“ Use the fine-tuned model to generate packing paths for new boxes.

---


